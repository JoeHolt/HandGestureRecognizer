{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this model i train a simple classifier\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "https://www.kaggle.com/gti-upm/leapgestrecog/version/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from load_dataset import process_img, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/joeholt/Documents/College Local/Current/CS 639/proj') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "dataset = load_dataset()\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 in channel, 6 new feature detectors, 5 kernel size, 1 stride (meaning output channels are same size)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16544, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('in:', x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print('pool1:', x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print('pool2:', x.shape)\n",
    "        x = x.view(-1, 16 * 22 * 47)\n",
    "        #print('x view:', x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('x fc1:', x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print('x fc2:', x.shape)\n",
    "        x = self.fc3(x)\n",
    "        #print('x fin:', x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 6 1 5 5, but got 3-dimensional input of size [100, 50, 50] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ffae216f80d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(len(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-44d2b54d042e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print('in:', x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print('pool1:', x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 6 1 5 5, but got 3-dimensional input of size [100, 50, 50] instead"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for Xi, yi in loader:\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(Xi)\n",
    "        \n",
    "        loss = criterion(outputs, yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if idx % 2000 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, idx + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    'palm': 0,\n",
    "    'l': 1,\n",
    "    'fist': 2,\n",
    "    'fist_moved': 3,\n",
    "    'thumb': 4,\n",
    "    'index': 5,\n",
    "    'ok': 6,\n",
    "    'palm_moved': 7,\n",
    "    'c': 8,\n",
    "    'down': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how it worked\n",
    "classes = list(class_labels.keys())\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    batch_size = 50\n",
    "    for idx in range(0, len(X) - batch_size, batch_size):\n",
    "        # get data\n",
    "        inputs = torch.FloatTensor(X[idx: idx + batch_size]).permute(0, 3, 1, 2)\n",
    "        labels = torch.LongTensor(y[idx: idx + batch_size])\n",
    "        # run through model\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # predict\n",
    "        for idx in range(outputs.shape[0]):\n",
    "            label = predicted[idx]\n",
    "            actual = labels[idx]\n",
    "            if actual == label:\n",
    "                class_correct[label] += 1\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3345.0, 202.0, 9508.0, 0.0, 517.0, 271.0, 1449.0, 0.0, 1838.0, 2820.0]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by class:\n",
      "\tpalm           acc = 0.457100\n",
      "\tl              acc = 0.896040\n",
      "\tfist           acc = 0.350126\n",
      "\tfist_moved     acc = 0.000000\n",
      "\tthumb          acc = 0.829787\n",
      "\tindex          acc = 0.118081\n",
      "\tok             acc = 0.628019\n",
      "\tpalm_moved     acc = 0.000000\n",
      "\tc              acc = 0.459195\n",
      "\tdown           acc = 0.471277\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy by class:\")\n",
    "for idx, c in enumerate(classes):\n",
    "    if class_total[idx] != 0:\n",
    "        print(\"\\t{:<12s}   acc = {:04f}\".format(c, class_correct[idx]/class_total[idx]))\n",
    "    else:\n",
    "        print(\"\\t{:<12s}   acc = {:04f}\".format(c, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(img):\n",
    "    in_to_model = torch.FloatTensor(img).permute(2, 0, 1).unsqueeze(0)\n",
    "    out = net(in_to_model)\n",
    "    _, predicted = torch.max(out, 1)\n",
    "    return labels[predicted]\n",
    "predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down predicted to be down\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 15000\n",
    "test = torch.FloatTensor(X[idx]).squeeze()\n",
    "imshow(test)\n",
    "print(\"{} predicted to be {}\".format(labels[y[idx]], predict(test.unsqueeze(2))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
