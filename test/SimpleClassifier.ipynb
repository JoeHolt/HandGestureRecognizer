{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this model i train a simple classifier\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "https://www.kaggle.com/gti-upm/leapgestrecog/version/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "os.chdir('/Users/joeholt/Documents/College Local/Current/CS 639/proj') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow = lambda im: plt.imshow(im, cmap='gray')\n",
    "def imshow_group(imgs):\n",
    "    f, axarr = plt.subplots(1,len(imgs), figsize=(20, 6))\n",
    "    for idx, img in enumerate(imgs):\n",
    "        axarr[idx].imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plus = os.path.join(os.getcwd(), 'data', 'leapGestRecog', '00', '01_palm', 'frame_00_01_0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee954c8828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_img(path, new_size, threshold=0.4):\n",
    "    img = img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (new_size[0],  new_size[1]))\n",
    "    img = cv2.threshold(img, 255*threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    return img\n",
    "    \n",
    "img = process_img(path_plus, (200, 100))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    'palm': 0,\n",
    "    'l': 1,\n",
    "    'fist': 2,\n",
    "    'fist_moved': 3,\n",
    "    'thumb': 4,\n",
    "    'index': 5,\n",
    "    'ok': 6,\n",
    "    'palm_moved': 7,\n",
    "    'c': 8,\n",
    "    'down': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(transformed_size=(100, 200)):\n",
    "    \"\"\"\n",
    "    Loads dataset and returns X, y. Loads dataset from leapGestRecog\n",
    "    data store in this project\n",
    "    \n",
    "    Returns:\n",
    "    X representing processed dataset images in arrays\n",
    "    y representing classes as strings for those items\n",
    "    \"\"\"\n",
    "    os.chdir('/Users/joeholt/Documents/College Local/Current/CS 639/proj')\n",
    "    root_data_dir = os.path.join(os.getcwd(), 'data', 'leapGestRecog')\n",
    "    \n",
    "    y = []\n",
    "    X = []\n",
    "    \n",
    "    # get data\n",
    "    for subject_dir in os.listdir(root_data_dir):\n",
    "        if subject_dir == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        \n",
    "        subject_path = os.path.join(root_data_dir, subject_dir)\n",
    "        \n",
    "        for class_dir in os.listdir(subject_path):\n",
    "            \n",
    "            class_path = os.path.join(subject_path, class_dir)\n",
    "            class_name = class_dir.split('_')[1]\n",
    "            \n",
    "            for filename in os.listdir(class_path):\n",
    "                \n",
    "                if filename.split('.')[1] != 'png':\n",
    "                    continue\n",
    "                \n",
    "                full_path = os.path.join(class_path, filename)\n",
    "                img = process_img(full_path, transformed_size[::-1])\n",
    "                \n",
    "                X.append(img)\n",
    "                y.append(class_name)\n",
    "    \n",
    "    # convert to numpy\n",
    "    X = np.array(X, dtype=\"uint8\")\n",
    "    X = X.reshape(len(X), transformed_size[0], transformed_size[1], 1)\n",
    "    y = [class_labels[itm] for itm in y]\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "transformed_img_size = (100, 200)\n",
    "X, y = load_dataset(transformed_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(y) == len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100, 200, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = (100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 in channel, 6 new feature detectors, 5 kernel size, 1 stride (meaning output channels are same size)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16544, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('in:', x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print('pool1:', x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print('pool2:', x.shape)\n",
    "        x = x.view(-1, 16 * 22 * 47)\n",
    "        #print('x view:', x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('x fc1:', x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print('x fc2:', x.shape)\n",
    "        x = self.fc3(x)\n",
    "        #print('x fin:', x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.001\n",
      "[1,  2001] loss: 0.045\n",
      "[1,  4001] loss: 0.045\n",
      "[1,  6001] loss: 0.045\n",
      "[1,  8001] loss: 0.044\n",
      "[1, 10001] loss: 0.045\n",
      "[1, 12001] loss: 0.042\n",
      "[1, 14001] loss: 0.043\n",
      "[1, 16001] loss: 0.044\n",
      "[1, 18001] loss: 0.041\n",
      "[2,     1] loss: 0.001\n",
      "[2,  2001] loss: 0.043\n",
      "[2,  4001] loss: 0.035\n",
      "[2,  6001] loss: 0.042\n",
      "[2,  8001] loss: 0.035\n",
      "[2, 10001] loss: 0.042\n",
      "[2, 12001] loss: 0.034\n",
      "[2, 14001] loss: 0.040\n",
      "[2, 16001] loss: 0.037\n",
      "[2, 18001] loss: 0.025\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    batch_size = 50\n",
    "    for idx in range(0, len(X) - batch_size, batch_size):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = torch.FloatTensor(X[idx: idx + batch_size]).permute(0, 3, 1, 2)\n",
    "        #print(inputs.shape)\n",
    "        labels = torch.LongTensor(y[idx: idx + batch_size])\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(len(outputs))\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if idx % 2000 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, idx + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    'palm': 0,\n",
    "    'l': 1,\n",
    "    'fist': 2,\n",
    "    'fist_moved': 3,\n",
    "    'thumb': 4,\n",
    "    'index': 5,\n",
    "    'ok': 6,\n",
    "    'palm_moved': 7,\n",
    "    'c': 8,\n",
    "    'down': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how it worked\n",
    "classes = list(class_labels.keys())\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    batch_size = 50\n",
    "    for idx in range(0, len(X) - batch_size, batch_size):\n",
    "        # get data\n",
    "        inputs = torch.FloatTensor(X[idx: idx + batch_size]).permute(0, 3, 1, 2)\n",
    "        labels = torch.LongTensor(y[idx: idx + batch_size])\n",
    "        # run through model\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # predict\n",
    "        for idx in range(outputs.shape[0]):\n",
    "            label = predicted[idx]\n",
    "            actual = labels[idx]\n",
    "            if actual == label:\n",
    "                class_correct[label] += 1\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3345.0, 202.0, 9508.0, 0.0, 517.0, 271.0, 1449.0, 0.0, 1838.0, 2820.0]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by class:\n",
      "\tpalm           acc = 0.457100\n",
      "\tl              acc = 0.896040\n",
      "\tfist           acc = 0.350126\n",
      "\tfist_moved     acc = 0.000000\n",
      "\tthumb          acc = 0.829787\n",
      "\tindex          acc = 0.118081\n",
      "\tok             acc = 0.628019\n",
      "\tpalm_moved     acc = 0.000000\n",
      "\tc              acc = 0.459195\n",
      "\tdown           acc = 0.471277\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy by class:\")\n",
    "for idx, c in enumerate(classes):\n",
    "    if class_total[idx] != 0:\n",
    "        print(\"\\t{:<12s}   acc = {:04f}\".format(c, class_correct[idx]/class_total[idx]))\n",
    "    else:\n",
    "        print(\"\\t{:<12s}   acc = {:04f}\".format(c, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(img):\n",
    "    in_to_model = torch.FloatTensor(img).permute(2, 0, 1).unsqueeze(0)\n",
    "    out = net(in_to_model)\n",
    "    _, predicted = torch.max(out, 1)\n",
    "    return labels[predicted]\n",
    "predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down predicted to be down\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 15000\n",
    "test = torch.FloatTensor(X[idx]).squeeze()\n",
    "imshow(test)\n",
    "print(\"{} predicted to be {}\".format(labels[y[idx]], predict(test.unsqueeze(2))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
